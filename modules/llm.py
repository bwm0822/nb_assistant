import ollama
import threading
if __name__ == "__main__":
    from speech import text_to_speech
else:
    from modules.speech import text_to_speech

LLM_MODEL_NAME = "llama3.2"

DEBUG = True
SPEAK = False
SPEECH = True

global current_thread
current_thread = None

pause_event = threading.Event()
stop_event = threading.Event()

prompt_main_1 = """
ä½ æ˜¯ä¸€å€‹æŒ‡ä»¤åˆ†æå™¨ï¼Œæ ¹æ“šä½ æ”¶åˆ°çš„è¨Šæ¯ï¼Œè½‰æ›æˆ
forward backward resume pause next play close query chat search çš„æŒ‡ä»¤ï¼Œ
è½‰æ›è¦å‰‡ï¼ŒæŒ‡ä»¤æ ¼å¼å¦‚ä¸‹ï¼š

1. è¨Šæ¯: å¿«è½‰       æŒ‡ä»¤æ ¼å¼:  forward æ™‚é–“è½‰æˆç§’æ•¸ï¼Œæ²’æœ‰æ™‚é–“å‰‡è¨­æˆ10
    ç¯„ä¾‹:
    å¿«è½‰            forward 10
    å¿«è½‰ æ™‚é–“       forward æ™‚é–“è½‰æˆç§’æ•¸

2. è¨Šæ¯: å€’è½‰       æŒ‡ä»¤æ ¼å¼:   backward æ™‚é–“è½‰æˆç§’æ•¸ï¼Œæ²’æœ‰æ™‚é–“å‰‡è¨­æˆ10
    ç¯„ä¾‹:
    å€’è½‰            backward 10 
    å€’è½‰ æ™‚é–“       backward æ™‚é–“è½‰æˆç§’æ•¸ 

3. è¨Šæ¯: ç¹¼çºŒ       æŒ‡ä»¤æ ¼å¼: resume
4. è¨Šæ¯: æš«åœ       æŒ‡ä»¤æ ¼å¼: pause
5. è¨Šæ¯: ä¸‹ä¸€å€‹     æŒ‡ä»¤æ ¼å¼: next

6. è¨Šæ¯: æœå°‹ é—œéµå­—    æŒ‡ä»¤æ ¼å¼:   play é—œéµå­—
   è¨Šæ¯: æœå°‹           æŒ‡ä»¤æ ¼å¼:   query è«‹å•è¦æœå°‹ä»€éº¼
    ç¯„ä¾‹:
    æœå°‹æŠ’æƒ…æ­Œ      play æŠ’æƒ…æ­Œ
    æœå°‹            query è«‹å•è¦æœå°‹ä»€éº¼

7. æ•˜è¿°: è½\æ’¥æ­Œ\æ’¥æ”¾ é—œéµå­—   æŒ‡ä»¤æ ¼å¼:    play é—œéµå­—
   æ•˜è¿°: è½\æ’¥æ­Œ\æ’¥æ”¾         æŒ‡ä»¤æ ¼å¼:     query è«‹å•è¦æ’¥çš„æ­Œ
    ç¯„ä¾‹:
    è½ä¼ä½°çš„æ­Œ      play ä¼ä½°çš„æ­Œ
    è½              query è«‹å•è¦è½ä»€éº¼

8. è¨Šæ¯: çœ‹\æˆ‘æƒ³çœ‹ é—œéµå­—     æŒ‡ä»¤æ ¼å¼:     play é—œéµå­—
   è¨Šæ¯: çœ‹\æˆ‘æƒ³çœ‹            æŒ‡ä»¤æ ¼å¼:     query è«‹å•è¦çœ‹ä»€éº¼
   ç¯„ä¾‹:
    æˆ‘æƒ³çœ‹æ–°è      play æ–°è
    æˆ‘æƒ³çœ‹          query è«‹å•è¦çœ‹ä»€éº¼

9. è¨Šæ¯: é—œé–‰               æŒ‡ä»¤æ ¼å¼:   close

10. æœå°‹ é—œéµå­—         æŒ‡ä»¤æ ¼å¼:   search é—œéµå­—
    ç¯„ä¾‹:
    æœå°‹é ­æ¢æ–°è        search é ­æ¢æ–°è

11. page            æŒ‡ä»¤æ ¼å¼:   page
    ç¯„ä¾‹:
        page        æŒ‡ä»¤æ ¼å¼:   page

11. å…¶ä»–ç„¡æ³•è­˜åˆ¥çš„æŒ‡ä»¤ï¼Œå¤©æ°£ã€äººåã€å•é¡Œ...ç­‰éƒ½ç•¶æˆèŠå¤©    æŒ‡ä»¤æ ¼å¼:   chat
    ç¯„ä¾‹:
    ä½ æ˜¯èª°ï¼Ÿ        chat
    ä½ æœƒä»€éº¼ï¼Ÿ      chat
    ä»Šå¤©å¹¾è™Ÿï¼Ÿ      chat
    ä½ å–œæ­¡ä»€éº¼ï¼Ÿ    chat
    èª°æ¯”è¼ƒå²å®³ï¼Ÿ    chat
    ç‰›é “            chat
    æ„›å› æ–¯å¦        chat
    é‡å­åŠ›å­¸        chat

Note:
1. è¿”å› æ ¼å¼å­—ä¸²ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„æ–‡å­—æˆ–èªªæ˜ã€‚
2. åªä½¿ç”¨ forward backward resume pause next play close query chat search ç•¶æŒ‡ä»¤ï¼Œ
    åƒè¬ä¸è¦è‡ªä½œè°æ˜ï¼Œä¸è¦è‡ªå‰µæŒ‡ä»¤ã€‚
3. é—œéµå­—ä¸è¦ç¿»æˆè‹±æ–‡ï¼Œç›´æ¥ç”¨åŸä¾†çš„é—œéµå­—ã€‚
"""

prompt_query = f"""
ä½ è©¢å•ä½¿ç”¨è€…ï¼Œæ ¹æ“šä½¿ç”¨è€…çš„å›ç­”ï¼Œè½‰æˆä»¥ä¸‹çš„æŒ‡ä»¤æ ¼å¼å­—ä¸²ï¼š
ä½¿ç”¨è€…çš„å›ç­”: å–æ¶ˆ               æŒ‡ä»¤æ ¼å¼:    cancel()
ä½¿ç”¨è€…çš„å›ç­”: å–æ¶ˆä¹‹å¤–çš„å›ç­”      æŒ‡ä»¤æ ¼å¼:     play(ä½¿ç”¨è€…çš„å›ç­”)
ç¯„ä¾‹:
å–æ¶ˆ                cancel()
å¿˜æƒ…æ°´              play(å¿˜æƒ…æ°´)
ä»Šå¤œä½ æœƒä¸æœƒä¾†      play(ä»Šå¤œä½ æœƒä¸æœƒä¾†)

Note:
1. è¿”å› æ ¼å¼å­—ä¸²ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„æ–‡å­—æˆ–èªªæ˜ã€‚
2. åªä½¿ç”¨ cancel play ç•¶æŒ‡ä»¤ï¼Œåƒè¬ä¸è¦è‡ªä½œè°æ˜ï¼Œä¸è¦è‡ªå‰µæŒ‡ä»¤ã€‚
3. æŒ‡ä»¤æ ¼å¼ç‚º æŒ‡ä»¤(é—œéµå­—)ï¼ŒæŒ‡ä»¤ä¸€å®šåŠ ()
4. é—œéµå­—ä¸è¦ç¿»æˆè‹±æ–‡ï¼Œç›´æ¥ç”¨åŸä¾†çš„é—œéµå­—ã€‚
"""

def thread(target, user_input):
    global current_thread
    if current_thread is not None:
        stop_event.set()    # åœæ­¢åŸ·è¡Œç·’
        pause_event.set()  # é˜²æ­¢é‚„åœ¨ç­‰å¾…
        print("---- wait ----")
        current_thread.join()
        print("---- done ----")

    pause_event.set()  # é è¨­ç‚ºä¸æš«åœç‹€æ…‹
    stop_event.clear()  # é è¨­ç‚ºä¸åœæ­¢ç‹€æ…‹
    # Create a thread to run the assistant_chat function
    current_thread = threading.Thread(target=target, args=(user_input,))
    current_thread.start()
    # Wait for the thread to finish
    # chat_thread.join()
    return {"status": 1, "msg": "åŸ·è¡Œç·’å•Ÿå‹•æˆåŠŸ"}


def assistant_main(user_input):
    response = ollama.chat(model=LLM_MODEL_NAME, messages=[
        {"role": "system", "content": prompt_main_1},
        {"role": "user", "content": user_input},
    ], stream=False)
    return response["message"]["content"]

def assistant_query(user_input):
    response = ollama.chat(model=LLM_MODEL_NAME, messages=[
        {"role": "system", "content": prompt_query},
        {"role": "user", "content": user_input},
    ], stream=False)
    return response["message"]["content"]
    # process_command(command, user_input)

def assistant_chat(user_input):
    # prompt = f"""
    # ä½ æ˜¯ä¸€å€‹æ€§æ„Ÿé¢¨é¨·çš„å¥³åƒ•ï¼Œè«‹ç”¨æŒ‘é€—çš„èªæ°£å›ç­”å•é¡Œã€‚
    # """
    prompt = f"""
    ä½ æ˜¯ä¸€å€‹æ™ºèƒ½èªéŸ³åŠ©æ‰‹ï¼Œè«‹ç”¨è¼•é¬†çš„èªæ°£å›ç­”å•é¡Œã€‚
    """
    response = ollama.chat(model=LLM_MODEL_NAME, messages=[
        {"role": "system", "content": prompt},
        {"role": "user", "content": user_input},
    ], stream=True)

    process_stream(response)
    global current_thread
    current_thread = None  # é‡ç½®åŸ·è¡Œç·’è®Šæ•¸
    print("---- åŸ·è¡Œç·’çµæŸ ----")


def process_stream(stream):
    print("Chatbot: ")
    full_response = ""
    for chunk in stream:

        if pause_event.is_set() is False:
            print("â¸ æš«åœè¼¸å‡º")
            pause_event.wait()

        if stop_event.is_set():
            print("ğŸ›‘ åœæ­¢åŸ·è¡Œç·’")
            return
        
        print(chunk['message']["content"], end='', flush=True)
        
        if SPEECH is True:
            # Collect the response in chunks
            full_response += chunk['message']["content"]
            if "\n" in full_response or any(p in full_response for p in "ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"):
                text_to_speech(full_response)
                full_response = ""
    if full_response:
        if SPEECH is True: text_to_speech(full_response)
    print('\n')

def execute(cmd, args):
    arg = args[0] if len(args) > 0 else ''
    match cmd:
        case "main":
            return assistant_main(arg)
        case "query":
            return assistant_query(arg)
        case "chat":
            return thread(assistant_chat, arg)
        case "pause":
            pause_event.clear()
            return {"status": 1, "msg": "æš«åœLLM"}
        case "resume":
            pause_event.set()
            return {"status": 1, "msg": "ç¹¼çºŒLLM"}
        case "stop":
            stop_event.set()    # åœæ­¢åŸ·è¡Œç·’
            pause_event.set()  # é˜²æ­¢é‚„åœ¨ç­‰å¾…
            return {"status": 1, "msg": "åœæ­¢åŸ·è¡Œç·’"}
        case _:
            return {"status": -1, "msg": "ç„¡æ•ˆçš„æŒ‡ä»¤"}



def unit_test():
    while True:
        user_input = input("è«‹è¼¸å…¥ä½ æƒ³è©¢å•çš„å•é¡Œï¼ŒæŒ‰ q é›¢é–‹\n")
        if user_input.lower() == "q": break
        sps = user_input.strip().split()
        print(sps, len(sps))
        if len(sps) > 0: cmd = sps[0]; args = sps[1:]
        else: cmd=''; args=[]
        print(f"æŒ‡ä»¤: {cmd}, åƒæ•¸: {args}")
        print(execute(cmd, args))


if __name__ == "__main__":
    unit_test()